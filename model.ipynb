{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e96a2bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk import pos_tag\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d467c449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ArticleId', 'Text', 'Category'], dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = pd.read_csv(\"BBC News Train.csv\")\n",
    "data_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b19ab746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['business', 'tech', 'politics', 'sport', 'entertainment']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_category = list(data_train.Category.unique())\n",
    "target_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e6b0d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocessing(train_text):\n",
    "       \n",
    "    #word tokenization using text-to-word-sequence\n",
    "    train_text= str(train_text)\n",
    "    filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'\n",
    "    tokenized_train_set = text_to_word_sequence(train_text,\n",
    "                                                filters = filters,\n",
    "                                                lower = True,\n",
    "                                                split=\" \")\n",
    "    #stop word removal\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    stopwordremove = [i for i in tokenized_train_set if not i in stop_words]\n",
    "        \n",
    "    #join words into sentence\n",
    "    stopwordremove_text = ' '.join(stopwordremove)\n",
    "        \n",
    "    #remove numbers\n",
    "    numberremove_text = ''.join(c for c in stopwordremove_text if not c.isdigit())\n",
    "    \n",
    "    #--Stemming--\n",
    "    stemmer= PorterStemmer()\n",
    "    stem_input=nltk.word_tokenize(numberremove_text)\n",
    "    stem_text=' '.join([stemmer.stem(word) for word in stem_input])\n",
    "   \n",
    "    def get_wordnet_pos(word):\n",
    "        \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "        tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "        tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "        return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "    lem_input = nltk.word_tokenize(stem_text)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lem_text= ' '.join([lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in lem_input])\n",
    "    return lem_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd6381ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train[\"Text\"] = data_train[\"Text\"].apply(preprocessing)\n",
    "text = data_train[\"Text\"]\n",
    "category = data_train['Category']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb84d6d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       worldcom ex bos launch defenc lawyer defend fo...\n",
       "1       german busi confid slide german busi confid fe...\n",
       "2       bbc poll indic econom gloom citizen major nati...\n",
       "3       lifestyl govern mobil choic faster well funkie...\n",
       "4       enron bos m payout eighteen former enron direc...\n",
       "                              ...                        \n",
       "1485    doubl evict big brother model capric holbi cit...\n",
       "1486    dj doubl act revamp chart show dj duo jk joel ...\n",
       "1487    weak dollar hit reuter revenu medium group reu...\n",
       "1488    appl ipod famili expand market appl expand ipo...\n",
       "1489    santi worm make unwelcom visit thousand websit...\n",
       "Name: Text, Length: 1490, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1a0810b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(text,category, \n",
    "                                                    test_size = 0.3, \n",
    "                                                    random_state = 60,\n",
    "                                                    shuffle=True, \n",
    "                                                    stratify=category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d486940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Train Accuracy Score : 99% \n",
      "Naive Bayes Test Accuracy Score  : 96% \n"
     ]
    }
   ],
   "source": [
    "nb = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "               ('clf', MultinomialNB())])\n",
    "nb.fit(X_train,Y_train)\n",
    "\n",
    "test_predict = nb.predict(X_test)\n",
    "\n",
    "train_accuracy = round(nb.score(X_train,Y_train)*100)\n",
    "test_accuracy =round(accuracy_score(test_predict, Y_test)*100)\n",
    "\n",
    "\n",
    "print(\"Naive Bayes Train Accuracy Score : {}% \".format(train_accuracy ))\n",
    "print(\"Naive Bayes Test Accuracy Score  : {}% \".format(test_accuracy ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe6b2eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test=pd.read_csv(\"BBC News Test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69e1e4ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ArticleId', 'Text'], dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "351220db",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test['Text'] = data_test['Text'].apply(preprocessing)\n",
    "\n",
    "test_id = data_test['ArticleId']\n",
    "test_text = data_test['Text']\n",
    "y_prdict = nb.predict(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c0dd965",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = pd.DataFrame(list(zip(test_id, y_prdict)),\n",
    "                          columns =['ArticleId', 'Category'])\n",
    "final_data.to_csv('news_sorted.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44cacc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = \"news_sorting.pkl\"\n",
    "pickle.dump(nb, open(filename,\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4a3be3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
